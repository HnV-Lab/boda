{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "densenet.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMCMUqnHVnSw",
        "colab_type": "text"
      },
      "source": [
        "## DenseNet\n",
        "\n",
        "- [Paper](https://arxiv.org/pdf/1608.06993.pdf)\n",
        "\n",
        "![](https://github.com/unerue/computer-vision/blob/master/img/densenet-02.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pckJJAnLV99-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8020b8e-0dc1-4133-bc80-781322e93377"
      },
      "source": [
        "!pip install torch-summary"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-summary in /usr/local/lib/python3.6/dist-packages (1.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlKSwVqZVnSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzJTZ6mMVnS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BnReluConv(nn.Sequential):\n",
        "    def __init__(self, nin: int, nout: int, kernel_size: int, stride: int, padding: int, bias: bool = False):\n",
        "        super().__init__()\n",
        "        self.add_module('batch_norm', nn.BatchNorm2d(nin))\n",
        "        self.add_module('relu', nn.ReLU(True))\n",
        "        self.add_module(\n",
        "            'conv',\n",
        "            nn.Conv2d(\n",
        "                in_channels=nin, \n",
        "                out_channels=nout, \n",
        "                kernel_size=kernel_size, \n",
        "                stride=stride, \n",
        "                padding=padding, \n",
        "                bias=bias\n",
        "            )\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = super().forward(x)        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY2Kj9pJVnS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BottleneckLayer(nn.Sequential):\n",
        "    \"\"\"Bottleneck Layer\n",
        "    Parameter\n",
        "    ---------\n",
        "    growth_rate : growth_rate of k\n",
        "    \"\"\"\n",
        "    def __init__(self, nin: int, growth_rate: int, dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.add_module(\n",
        "            'conv_1x1',\n",
        "            BnReluConv(\n",
        "                nin=nin, \n",
        "                nout=growth_rate*4, \n",
        "                kernel_size=1, \n",
        "                stride=1, \n",
        "                padding=0, \n",
        "                bias=False\n",
        "            )\n",
        "        )\n",
        "        self.add_module(\n",
        "            'conv_3x3', \n",
        "            BnReluConv(\n",
        "                nin=growth_rate*4, \n",
        "                nout=growth_rate, \n",
        "                kernel_size=3, \n",
        "                stride=1, \n",
        "                padding=1, \n",
        "                bias=False\n",
        "            )\n",
        "        )\n",
        "        self.dropout = dropout\n",
        "      \n",
        "    def forward(self, x):\n",
        "        output = super().forward(x)\n",
        "        if self.dropout > 0:\n",
        "            bottleneck_output = F.dropout(\n",
        "                input=output, \n",
        "                p=self.dropout, \n",
        "                training=self.training\n",
        "            )\n",
        "        output = torch.cat((x, output), 1)\n",
        "      \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9tqaLqdVnS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransitionLayer(nn.Sequential):\n",
        "    def __init__(self, nin: int, theta: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.add_module(\n",
        "            'conv_1x1', \n",
        "            BnReluConv(\n",
        "                nin=nin,\n",
        "                nout=int(nin*theta),\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                bias=False\n",
        "            )\n",
        "        )\n",
        "        self.add_module(\n",
        "            'avg_pool_2x2',\n",
        "            nn.AvgPool2d(\n",
        "                kernel_size=2,\n",
        "                stride=2,\n",
        "                padding=0\n",
        "            )\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BsXKyoBVnS7",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/unerue/computer-vision/blob/master/img/densenet-01.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYPyMzjoVnS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenseBlock(nn.Sequential):\n",
        "    def __init__(self, nin: int, num_bottleneck_layers: int, growth_rate: int, dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        for i in range(num_bottleneck_layers):\n",
        "            nin_bottleneck_layer = nin + growth_rate * i\n",
        "            self.add_module(\n",
        "                f'bottleneck_layer_{i:d}', \n",
        "                BottleneckLayer(\n",
        "                    nin=nin_bottleneck_layer,\n",
        "                    growth_rate=growth_rate,\n",
        "                    dropout=dropout\n",
        "                )\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzLSPsrsVnS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, growth_rate=12, num_layers=100, theta=0.5, dropout=0.2, num_classes=10):\n",
        "        super().__init__()\n",
        "        assert (num_layers - 4) % 6 == 0\n",
        "        \n",
        "        # (num_layers-4)//6 \n",
        "        num_bottleneck_layers = (num_layers - 4) // 6\n",
        "        \n",
        "        # 32 x 32 x 3 --> 32 x 32 x (growth_rate*2)\n",
        "        self.init_conv = nn.Conv2d(\n",
        "            in_channels=3,\n",
        "            out_channels=growth_rate*2, \n",
        "            kernel_size=3, \n",
        "            stride=1, \n",
        "            padding=1,\n",
        "            bias=True\n",
        "        )\n",
        "        # 32 x 32 x (growth_rate*2) --> 32 x 32 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)]\n",
        "        self.dense_block_1 = DenseBlock(\n",
        "            nin=growth_rate*2, \n",
        "            num_bottleneck_layers=num_bottleneck_layers, \n",
        "            growth_rate=growth_rate, \n",
        "            dropout=dropout\n",
        "        )\n",
        "        # 32 x 32 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)] --> 16 x 16 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)]*theta\n",
        "        nin_transition_layer_1 = (growth_rate*2) + (growth_rate * num_bottleneck_layers) \n",
        "        self.transition_layer_1 = TransitionLayer(\n",
        "            nin=nin_transition_layer_1,\n",
        "            theta=theta\n",
        "        )\n",
        "        # 16 x 16 x nin_transition_layer_1*theta --> 16 x 16 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)]\n",
        "        self.dense_block_2 = DenseBlock(\n",
        "            nin=int(nin_transition_layer_1*theta), \n",
        "            num_bottleneck_layers=num_bottleneck_layers,\n",
        "            growth_rate=growth_rate, \n",
        "            dropout=dropout\n",
        "        )\n",
        "        # 16 x 16 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)] --> 8 x 8 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)]*theta\n",
        "        nin_transition_layer_2 = int(nin_transition_layer_1*theta) + (growth_rate * num_bottleneck_layers) \n",
        "        self.transition_layer_2 = TransitionLayer(\n",
        "            nin=nin_transition_layer_2,\n",
        "            theta=theta\n",
        "        )\n",
        "        # 8 x 8 x nin_transition_layer_2*theta --> 8 x 8 x [nin_transition_layer_2*theta + (growth_rate * num_bottleneck_layers)]\n",
        "        self.dense_block_3 = DenseBlock(\n",
        "            nin=int(nin_transition_layer_2*theta), \n",
        "            num_bottleneck_layers=num_bottleneck_layers,\n",
        "            growth_rate=growth_rate, \n",
        "            dropout=dropout\n",
        "        )\n",
        "        nin_fc_layer = int(nin_transition_layer_2*theta) + (growth_rate * num_bottleneck_layers) \n",
        "        \n",
        "        # [nin_transition_layer_2*theta + (growth_rate * num_bottleneck_layers)] --> num_classes\n",
        "        self.fc_layer = nn.Linear(nin_fc_layer, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        dense_init_output = self.init_conv(x)\n",
        "        \n",
        "        dense_block_1_output = self.dense_block_1(dense_init_output)\n",
        "        transition_layer_1_output = self.transition_layer_1(dense_block_1_output)\n",
        "        \n",
        "        dense_block_2_output = self.dense_block_2(transition_layer_1_output)\n",
        "        transition_layer_2_output = self.transition_layer_2(dense_block_2_output)\n",
        "        \n",
        "        dense_block_3_output = self.dense_block_3(transition_layer_2_output)\n",
        "        \n",
        "        global_avg_pool_output = F.adaptive_avg_pool2d(dense_block_3_output, (1, 1))                \n",
        "        global_avg_pool_output_flat = global_avg_pool_output.view(global_avg_pool_output.size(0), -1)\n",
        "\n",
        "        output = self.fc_layer(global_avg_pool_output_flat)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0ZdHEYXVnTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def densenet_121():\n",
        "    return DenseNet(\n",
        "        growth_rate=12,\n",
        "        num_layers=40, \n",
        "        theta=0.5, \n",
        "        dropout=0.2, \n",
        "        num_classes=10\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZAh-0LVVnTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = densenet_121().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js1rIiDKVnTE",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/unerue/computer-vision/blob/master/img/densenet-03.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_TtuHXcVnTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9e0fa91-abbc-4679-c775-e59084a97bf3"
      },
      "source": [
        "summary(net, input_data=(3, 32, 32), verbose=0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "------------------------------------------------------------------------------------------\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Conv2d: 1-1                            [-1, 24, 32, 32]          672\n",
              "├─DenseBlock: 1-2                        [-1, 96, 32, 32]          --\n",
              "|    └─BottleneckLayer: 2-1              [-1, 36, 32, 32]          --\n",
              "|    |    └─BnReluConv: 3-1              [-1, 48, 32, 32]          1,200\n",
              "|    |    └─BnReluConv: 3-2              [-1, 12, 32, 32]          5,280\n",
              "|    └─BottleneckLayer: 2-2              [-1, 48, 32, 32]          --\n",
              "|    |    └─BnReluConv: 3-3              [-1, 48, 32, 32]          1,800\n",
              "|    |    └─BnReluConv: 3-4              [-1, 12, 32, 32]          5,280\n",
              "|    └─BottleneckLayer: 2-3              [-1, 60, 32, 32]          --\n",
              "|    |    └─BnReluConv: 3-5              [-1, 48, 32, 32]          2,400\n",
              "|    |    └─BnReluConv: 3-6              [-1, 12, 32, 32]          5,280\n",
              "|    └─BottleneckLayer: 2-4              [-1, 72, 32, 32]          --\n",
              "|    |    └─BnReluConv: 3-7              [-1, 48, 32, 32]          3,000\n",
              "|    |    └─BnReluConv: 3-8              [-1, 12, 32, 32]          5,280\n",
              "|    └─BottleneckLayer: 2-5              [-1, 84, 32, 32]          --\n",
              "|    |    └─BnReluConv: 3-9              [-1, 48, 32, 32]          3,600\n",
              "|    |    └─BnReluConv: 3-10             [-1, 12, 32, 32]          5,280\n",
              "|    └─BottleneckLayer: 2-6              [-1, 96, 32, 32]          --\n",
              "|    |    └─BnReluConv: 3-11             [-1, 48, 32, 32]          4,200\n",
              "|    |    └─BnReluConv: 3-12             [-1, 12, 32, 32]          5,280\n",
              "├─TransitionLayer: 1-3                   [-1, 48, 16, 16]          --\n",
              "|    └─BnReluConv: 2-7                   [-1, 48, 32, 32]          --\n",
              "|    |    └─BatchNorm2d: 3-13            [-1, 96, 32, 32]          192\n",
              "|    |    └─ReLU: 3-14                   [-1, 96, 32, 32]          --\n",
              "|    |    └─Conv2d: 3-15                 [-1, 48, 32, 32]          4,608\n",
              "|    └─AvgPool2d: 2-8                    [-1, 48, 16, 16]          --\n",
              "├─DenseBlock: 1-4                        [-1, 120, 16, 16]         --\n",
              "|    └─BottleneckLayer: 2-9              [-1, 60, 16, 16]          --\n",
              "|    |    └─BnReluConv: 3-16             [-1, 48, 16, 16]          2,400\n",
              "|    |    └─BnReluConv: 3-17             [-1, 12, 16, 16]          5,280\n",
              "|    └─BottleneckLayer: 2-10             [-1, 72, 16, 16]          --\n",
              "|    |    └─BnReluConv: 3-18             [-1, 48, 16, 16]          3,000\n",
              "|    |    └─BnReluConv: 3-19             [-1, 12, 16, 16]          5,280\n",
              "|    └─BottleneckLayer: 2-11             [-1, 84, 16, 16]          --\n",
              "|    |    └─BnReluConv: 3-20             [-1, 48, 16, 16]          3,600\n",
              "|    |    └─BnReluConv: 3-21             [-1, 12, 16, 16]          5,280\n",
              "|    └─BottleneckLayer: 2-12             [-1, 96, 16, 16]          --\n",
              "|    |    └─BnReluConv: 3-22             [-1, 48, 16, 16]          4,200\n",
              "|    |    └─BnReluConv: 3-23             [-1, 12, 16, 16]          5,280\n",
              "|    └─BottleneckLayer: 2-13             [-1, 108, 16, 16]         --\n",
              "|    |    └─BnReluConv: 3-24             [-1, 48, 16, 16]          4,800\n",
              "|    |    └─BnReluConv: 3-25             [-1, 12, 16, 16]          5,280\n",
              "|    └─BottleneckLayer: 2-14             [-1, 120, 16, 16]         --\n",
              "|    |    └─BnReluConv: 3-26             [-1, 48, 16, 16]          5,400\n",
              "|    |    └─BnReluConv: 3-27             [-1, 12, 16, 16]          5,280\n",
              "├─TransitionLayer: 1-5                   [-1, 60, 8, 8]            --\n",
              "|    └─BnReluConv: 2-15                  [-1, 60, 16, 16]          --\n",
              "|    |    └─BatchNorm2d: 3-28            [-1, 120, 16, 16]         240\n",
              "|    |    └─ReLU: 3-29                   [-1, 120, 16, 16]         --\n",
              "|    |    └─Conv2d: 3-30                 [-1, 60, 16, 16]          7,200\n",
              "|    └─AvgPool2d: 2-16                   [-1, 60, 8, 8]            --\n",
              "├─DenseBlock: 1-6                        [-1, 132, 8, 8]           --\n",
              "|    └─BottleneckLayer: 2-17             [-1, 72, 8, 8]            --\n",
              "|    |    └─BnReluConv: 3-31             [-1, 48, 8, 8]            3,000\n",
              "|    |    └─BnReluConv: 3-32             [-1, 12, 8, 8]            5,280\n",
              "|    └─BottleneckLayer: 2-18             [-1, 84, 8, 8]            --\n",
              "|    |    └─BnReluConv: 3-33             [-1, 48, 8, 8]            3,600\n",
              "|    |    └─BnReluConv: 3-34             [-1, 12, 8, 8]            5,280\n",
              "|    └─BottleneckLayer: 2-19             [-1, 96, 8, 8]            --\n",
              "|    |    └─BnReluConv: 3-35             [-1, 48, 8, 8]            4,200\n",
              "|    |    └─BnReluConv: 3-36             [-1, 12, 8, 8]            5,280\n",
              "|    └─BottleneckLayer: 2-20             [-1, 108, 8, 8]           --\n",
              "|    |    └─BnReluConv: 3-37             [-1, 48, 8, 8]            4,800\n",
              "|    |    └─BnReluConv: 3-38             [-1, 12, 8, 8]            5,280\n",
              "|    └─BottleneckLayer: 2-21             [-1, 120, 8, 8]           --\n",
              "|    |    └─BnReluConv: 3-39             [-1, 48, 8, 8]            5,400\n",
              "|    |    └─BnReluConv: 3-40             [-1, 12, 8, 8]            5,280\n",
              "|    └─BottleneckLayer: 2-22             [-1, 132, 8, 8]           --\n",
              "|    |    └─BnReluConv: 3-41             [-1, 48, 8, 8]            6,000\n",
              "|    |    └─BnReluConv: 3-42             [-1, 12, 8, 8]            5,280\n",
              "├─Linear: 1-7                            [-1, 10]                  1,330\n",
              "==========================================================================================\n",
              "Total params: 175,882\n",
              "Trainable params: 175,882\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 72.87\n",
              "------------------------------------------------------------------------------------------\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 12.02\n",
              "Params size (MB): 0.67\n",
              "Estimated Total Size (MB): 12.70\n",
              "------------------------------------------------------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUambXpDVnTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}