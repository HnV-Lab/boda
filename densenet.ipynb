{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet\n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/1608.06993.pdf)\n",
    "\n",
    "![](img/densenet-02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnReluConv(nn.Sequential):\n",
    "    def __init__(self, nin, nout, kernel_size, stride, padding, bias=False):\n",
    "        super().__init__()\n",
    "        self.add_module(\n",
    "            'batch_norm', \n",
    "            nn.BatchNorm2d(nin)\n",
    "        )\n",
    "        self.add_module(\n",
    "            'relu', \n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.add_module(\n",
    "            'conv',\n",
    "            nn.Conv2d(\n",
    "                in_channels=nin, \n",
    "                out_channels=nout, \n",
    "                kernel_size=kernel_size, \n",
    "                stride=stride, \n",
    "                padding=padding, \n",
    "                bias=bias\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = super().forward(x)        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckLayer(nn.Sequential):\n",
    "    \"\"\"Bottleneck Layer\n",
    "    growth_rate : growth_rate of k\n",
    "    \"\"\"\n",
    "    def __init__(self, nin, growth_rate, drop_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.add_module(\n",
    "            'conv_1x1',\n",
    "            BnReluConv(\n",
    "                nin=nin, \n",
    "                nout=growth_rate*4, \n",
    "                kernel_size=1, \n",
    "                stride=1, \n",
    "                padding=0, \n",
    "                bias=False\n",
    "            )\n",
    "        )\n",
    "        self.add_module(\n",
    "            'conv_3x3', \n",
    "            BnReluConv(\n",
    "                nin=growth_rate*4, \n",
    "                nout=growth_rate, \n",
    "                kernel_size=3, \n",
    "                stride=1, \n",
    "                padding=1, \n",
    "                bias=False\n",
    "            )\n",
    "        )\n",
    "        self.drop_rate = drop_rate\n",
    "      \n",
    "    def forward(self, x):\n",
    "        output = super().forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            bottleneck_output = F.dropout(\n",
    "                input=output, \n",
    "                p=self.drop_rate, \n",
    "                training=self.training\n",
    "            )\n",
    "        output = torch.cat((x, output), 1)\n",
    "      \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionLayer(nn.Sequential):\n",
    "    def __init__(self, nin, theta=0.5):\n",
    "        super().__init__()\n",
    "        self.add_module(\n",
    "            'conv_1x1', \n",
    "            BnReluConv(\n",
    "                nin=nin,\n",
    "                nout=int(nin*theta),\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False\n",
    "            )\n",
    "        )\n",
    "        self.add_module(\n",
    "            'avg_pool_2x2',\n",
    "            nn.AvgPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                padding=0\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/densenet-01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Sequential):\n",
    "    def __init__(self, nin, num_bottleneck_layers, growth_rate, drop_rate=0.2):\n",
    "        super().__init__()\n",
    "        for i in range(num_bottleneck_layers):\n",
    "            nin_bottleneck_layer = nin + growth_rate * i\n",
    "            self.add_module(\n",
    "                f'bottleneck_layer_{i:d}', \n",
    "                BottleneckLayer(\n",
    "                    nin=nin_bottleneck_layer,\n",
    "                    growth_rate=growth_rate,\n",
    "                    drop_rate=drop_rate\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growth_rate=12, num_layers=100, theta=0.5, drop_rate=0.2, num_classes=10):\n",
    "        super().__init__()\n",
    "        assert (num_layers - 4) % 6 == 0\n",
    "        \n",
    "        # (num_layers-4)//6 \n",
    "        num_bottleneck_layers = (num_layers - 4) // 6\n",
    "        \n",
    "        # 32 x 32 x 3 --> 32 x 32 x (growth_rate*2)\n",
    "        self.init_conv = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=growth_rate*2, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1,\n",
    "            bias=True\n",
    "        )\n",
    "        # 32 x 32 x (growth_rate*2) --> 32 x 32 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)]\n",
    "        self.dense_block_1 = DenseBlock(\n",
    "            nin=growth_rate*2, \n",
    "            num_bottleneck_layers=num_bottleneck_layers, \n",
    "            growth_rate=growth_rate, \n",
    "            drop_rate=drop_rate\n",
    "        )\n",
    "        # 32 x 32 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)] --> 16 x 16 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)]*theta\n",
    "        nin_transition_layer_1 = (growth_rate*2) + (growth_rate * num_bottleneck_layers) \n",
    "        self.transition_layer_1 = TransitionLayer(\n",
    "            nin=nin_transition_layer_1,\n",
    "            theta=theta\n",
    "        )\n",
    "        # 16 x 16 x nin_transition_layer_1*theta --> 16 x 16 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)]\n",
    "        self.dense_block_2 = DenseBlock(\n",
    "            nin=int(nin_transition_layer_1*theta), \n",
    "            num_bottleneck_layers=num_bottleneck_layers,\n",
    "            growth_rate=growth_rate, \n",
    "            drop_rate=drop_rate\n",
    "        )\n",
    "        # 16 x 16 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)] --> 8 x 8 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)]*theta\n",
    "        nin_transition_layer_2 = int(nin_transition_layer_1*theta) + (growth_rate * num_bottleneck_layers) \n",
    "        self.transition_layer_2 = TransitionLayer(\n",
    "            nin=nin_transition_layer_2,\n",
    "            theta=theta\n",
    "        )\n",
    "        # 8 x 8 x nin_transition_layer_2*theta --> 8 x 8 x [nin_transition_layer_2*theta + (growth_rate * num_bottleneck_layers)]\n",
    "        self.dense_block_3 = DenseBlock(\n",
    "            nin=int(nin_transition_layer_2*theta), \n",
    "            num_bottleneck_layers=num_bottleneck_layers,\n",
    "            growth_rate=growth_rate, \n",
    "            drop_rate=drop_rate\n",
    "        )\n",
    "        nin_fc_layer = int(nin_transition_layer_2*theta) + (growth_rate * num_bottleneck_layers) \n",
    "        \n",
    "        # [nin_transition_layer_2*theta + (growth_rate * num_bottleneck_layers)] --> num_classes\n",
    "        self.fc_layer = nn.Linear(nin_fc_layer, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dense_init_output = self.init_conv(x)\n",
    "        \n",
    "        dense_block_1_output = self.dense_block_1(dense_init_output)\n",
    "        transition_layer_1_output = self.transition_layer_1(dense_block_1_output)\n",
    "        \n",
    "        dense_block_2_output = self.dense_block_2(transition_layer_1_output)\n",
    "        transition_layer_2_output = self.transition_layer_2(dense_block_2_output)\n",
    "        \n",
    "        dense_block_3_output = self.dense_block_3(transition_layer_2_output)\n",
    "        \n",
    "        global_avg_pool_output = F.adaptive_avg_pool2d(dense_block_3_output, (1, 1))                \n",
    "        global_avg_pool_output_flat = global_avg_pool_output.view(global_avg_pool_output.size(0), -1)\n",
    "\n",
    "        output = self.fc_layer(global_avg_pool_output_flat)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def densenet_121():\n",
    "    return DenseNet(\n",
    "        growth_rate=12,\n",
    "        num_layers=40, \n",
    "        theta=0.5, \n",
    "        drop_rate=0.2, \n",
    "        num_classes=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = densenet_121().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/densenet-03.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "------------------------------------------------------------------------------------------\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 24, 32, 32]          672\n",
       "├─DenseBlock: 1-2                        [-1, 96, 32, 32]          --\n",
       "|    └─BottleneckLayer: 2-1              [-1, 36, 32, 32]          --\n",
       "|    |    └─BnReluConv: 3-1              [-1, 48, 32, 32]          1,200\n",
       "|    |    └─BnReluConv: 3-2              [-1, 12, 32, 32]          5,280\n",
       "|    └─BottleneckLayer: 2-2              [-1, 48, 32, 32]          --\n",
       "|    |    └─BnReluConv: 3-3              [-1, 48, 32, 32]          1,800\n",
       "|    |    └─BnReluConv: 3-4              [-1, 12, 32, 32]          5,280\n",
       "|    └─BottleneckLayer: 2-3              [-1, 60, 32, 32]          --\n",
       "|    |    └─BnReluConv: 3-5              [-1, 48, 32, 32]          2,400\n",
       "|    |    └─BnReluConv: 3-6              [-1, 12, 32, 32]          5,280\n",
       "|    └─BottleneckLayer: 2-4              [-1, 72, 32, 32]          --\n",
       "|    |    └─BnReluConv: 3-7              [-1, 48, 32, 32]          3,000\n",
       "|    |    └─BnReluConv: 3-8              [-1, 12, 32, 32]          5,280\n",
       "|    └─BottleneckLayer: 2-5              [-1, 84, 32, 32]          --\n",
       "|    |    └─BnReluConv: 3-9              [-1, 48, 32, 32]          3,600\n",
       "|    |    └─BnReluConv: 3-10             [-1, 12, 32, 32]          5,280\n",
       "|    └─BottleneckLayer: 2-6              [-1, 96, 32, 32]          --\n",
       "|    |    └─BnReluConv: 3-11             [-1, 48, 32, 32]          4,200\n",
       "|    |    └─BnReluConv: 3-12             [-1, 12, 32, 32]          5,280\n",
       "├─TransitionLayer: 1-3                   [-1, 48, 16, 16]          --\n",
       "|    └─BnReluConv: 2-7                   [-1, 48, 32, 32]          --\n",
       "|    |    └─BatchNorm2d: 3-13            [-1, 96, 32, 32]          192\n",
       "|    |    └─ReLU: 3-14                   [-1, 96, 32, 32]          --\n",
       "|    |    └─Conv2d: 3-15                 [-1, 48, 32, 32]          4,608\n",
       "|    └─AvgPool2d: 2-8                    [-1, 48, 16, 16]          --\n",
       "├─DenseBlock: 1-4                        [-1, 120, 16, 16]         --\n",
       "|    └─BottleneckLayer: 2-9              [-1, 60, 16, 16]          --\n",
       "|    |    └─BnReluConv: 3-16             [-1, 48, 16, 16]          2,400\n",
       "|    |    └─BnReluConv: 3-17             [-1, 12, 16, 16]          5,280\n",
       "|    └─BottleneckLayer: 2-10             [-1, 72, 16, 16]          --\n",
       "|    |    └─BnReluConv: 3-18             [-1, 48, 16, 16]          3,000\n",
       "|    |    └─BnReluConv: 3-19             [-1, 12, 16, 16]          5,280\n",
       "|    └─BottleneckLayer: 2-11             [-1, 84, 16, 16]          --\n",
       "|    |    └─BnReluConv: 3-20             [-1, 48, 16, 16]          3,600\n",
       "|    |    └─BnReluConv: 3-21             [-1, 12, 16, 16]          5,280\n",
       "|    └─BottleneckLayer: 2-12             [-1, 96, 16, 16]          --\n",
       "|    |    └─BnReluConv: 3-22             [-1, 48, 16, 16]          4,200\n",
       "|    |    └─BnReluConv: 3-23             [-1, 12, 16, 16]          5,280\n",
       "|    └─BottleneckLayer: 2-13             [-1, 108, 16, 16]         --\n",
       "|    |    └─BnReluConv: 3-24             [-1, 48, 16, 16]          4,800\n",
       "|    |    └─BnReluConv: 3-25             [-1, 12, 16, 16]          5,280\n",
       "|    └─BottleneckLayer: 2-14             [-1, 120, 16, 16]         --\n",
       "|    |    └─BnReluConv: 3-26             [-1, 48, 16, 16]          5,400\n",
       "|    |    └─BnReluConv: 3-27             [-1, 12, 16, 16]          5,280\n",
       "├─TransitionLayer: 1-5                   [-1, 60, 8, 8]            --\n",
       "|    └─BnReluConv: 2-15                  [-1, 60, 16, 16]          --\n",
       "|    |    └─BatchNorm2d: 3-28            [-1, 120, 16, 16]         240\n",
       "|    |    └─ReLU: 3-29                   [-1, 120, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-30                 [-1, 60, 16, 16]          7,200\n",
       "|    └─AvgPool2d: 2-16                   [-1, 60, 8, 8]            --\n",
       "├─DenseBlock: 1-6                        [-1, 132, 8, 8]           --\n",
       "|    └─BottleneckLayer: 2-17             [-1, 72, 8, 8]            --\n",
       "|    |    └─BnReluConv: 3-31             [-1, 48, 8, 8]            3,000\n",
       "|    |    └─BnReluConv: 3-32             [-1, 12, 8, 8]            5,280\n",
       "|    └─BottleneckLayer: 2-18             [-1, 84, 8, 8]            --\n",
       "|    |    └─BnReluConv: 3-33             [-1, 48, 8, 8]            3,600\n",
       "|    |    └─BnReluConv: 3-34             [-1, 12, 8, 8]            5,280\n",
       "|    └─BottleneckLayer: 2-19             [-1, 96, 8, 8]            --\n",
       "|    |    └─BnReluConv: 3-35             [-1, 48, 8, 8]            4,200\n",
       "|    |    └─BnReluConv: 3-36             [-1, 12, 8, 8]            5,280\n",
       "|    └─BottleneckLayer: 2-20             [-1, 108, 8, 8]           --\n",
       "|    |    └─BnReluConv: 3-37             [-1, 48, 8, 8]            4,800\n",
       "|    |    └─BnReluConv: 3-38             [-1, 12, 8, 8]            5,280\n",
       "|    └─BottleneckLayer: 2-21             [-1, 120, 8, 8]           --\n",
       "|    |    └─BnReluConv: 3-39             [-1, 48, 8, 8]            5,400\n",
       "|    |    └─BnReluConv: 3-40             [-1, 12, 8, 8]            5,280\n",
       "|    └─BottleneckLayer: 2-22             [-1, 132, 8, 8]           --\n",
       "|    |    └─BnReluConv: 3-41             [-1, 48, 8, 8]            6,000\n",
       "|    |    └─BnReluConv: 3-42             [-1, 12, 8, 8]            5,280\n",
       "├─Linear: 1-7                            [-1, 10]                  1,330\n",
       "==========================================================================================\n",
       "Total params: 175,882\n",
       "Trainable params: 175,882\n",
       "Non-trainable params: 0\n",
       "------------------------------------------------------------------------------------------\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 12.02\n",
       "Params size (MB): 0.67\n",
       "Estimated Total Size (MB): 12.70\n",
       "------------------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net, input_data=(3, 32, 32), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
